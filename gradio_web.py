import gradio as gr
import json
import os
import traceback
from transcribe import Transcribe
from zipfile import ZipFile
import base64
import io
import ffmpeg
from translation import GPT, Baidu, Tencent, translation
from utils import extract_audio, merge_subtitles_to_video, clear_folder, import_config_file
from uvr import UVR_Client

# ä¸´æ—¶æ–‡ä»¶å­˜æ”¾åœ°å€
TEMP = "./temp"

# å…¨å±€å˜é‡å­˜å‚¨çŠ¶æ€
class AppState:
    def __init__(self):
        self.transcribe = None
        self.config = None
        self.audio_temp = None
        self.video_temp = None
        self.video_temp_name = None
        self.audio_separator_temp = None
        self.uvr_client = None
        self.engine = None
        
        # é»˜è®¤é…ç½®
        self.model_list = ["tiny", "base", "small", "medium", "large-v2", "large-v3",
                          "tiny.en", "base.en", "medium.en", "small.en"]
        self.model_name = "large-v2"
        self.chat_url = "https://api.openai.com/v1"
        self.chat_key = ""
        self.chat_model_list = ["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo"]
        self.chat_model_name = "gpt-4-turbo"
        self.baidu_appid = ""
        self.baidu_appkey = ""
        self.tencent_appid = ""
        self.tencent_secretKey = ""

app_state = AppState()

def load_config(config_file):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    if config_file is None:
        return "è¯·é€‰æ‹©é…ç½®æ–‡ä»¶", gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), gr.update()
    
    try:
        with open(config_file.name, 'r', encoding='utf-8') as f:
            config_data = json.load(f)
        
        app_state.config = config_data
        
        # æ›´æ–°å„ç§é…ç½®
        model_name = config_data.get("model_name", app_state.model_name)
        chat_url = config_data.get("chat_url", app_state.chat_url)
        chat_key = config_data.get("chat_key", app_state.chat_key)
        chat_model = config_data.get("chat_model_name", app_state.chat_model_name)
        baidu_appid = config_data.get("baidu_appid", app_state.baidu_appid)
        baidu_appkey = config_data.get("baidu_appkey", app_state.baidu_appkey)
        tencent_appid = config_data.get("tencent_appid", app_state.tencent_appid)
        tencent_secretkey = config_data.get("tencent_secretKey", app_state.tencent_secretKey)
        
        return ("é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸï¼", 
                gr.update(value=model_name),
                gr.update(value=chat_url),
                gr.update(value=chat_key),
                gr.update(value=chat_model),
                gr.update(value=baidu_appid),
                gr.update(value=baidu_appkey),
                gr.update(value=tencent_appid),
                gr.update(value=tencent_secretkey))
    except Exception as e:
        return f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}", gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), gr.update()

def load_model(model_name, device_name, custom_model_path=None):
    """åŠ è½½è½¬å½•æ¨¡å‹"""
    try:
        if app_state.transcribe is not None:
            del app_state.transcribe
        
        # ä¼˜å…ˆä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„
        if custom_model_path and os.path.exists(custom_model_path):
            print(f"åŠ è½½è‡ªå®šä¹‰æœ¬åœ°æ¨¡å‹ï¼š{custom_model_path}")
            app_state.transcribe = Transcribe(model_name=custom_model_path, device=device_name)
            model_display_name = os.path.basename(custom_model_path)
            return f"è‡ªå®šä¹‰æ¨¡å‹åŠ è½½æˆåŠŸï¼š{model_display_name} (è®¾å¤‡: {device_name})"
        
        # æ£€æŸ¥æ ‡å‡†æ¨¡å‹è·¯å¾„
        models_path = "./models" + "/faster-whisper-" + model_name
        
        if os.path.exists(models_path):
            print(f"åŠ è½½æœ¬åœ°æ¨¡å‹ï¼š{models_path}")
            app_state.transcribe = Transcribe(model_name=models_path, device=device_name)
        else:
            print(f"åŠ è½½HuggingFaceæ¨¡å‹ï¼š{model_name}")
            app_state.transcribe = Transcribe(model_name=model_name, device=device_name)
        
        app_state.model_name = model_name
        return f"æ¨¡å‹åŠ è½½æˆåŠŸï¼š{model_name} (è®¾å¤‡: {device_name})"
    except Exception as e:
        return f"æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)}"

def clear_cache():
    """æ¸…ç©ºç¼“å­˜"""
    try:
        clear_folder("./temp")
        app_state.audio_temp = None
        app_state.video_temp = None
        app_state.audio_separator_temp = None
        return "ç¼“å­˜æ¸…ç©ºæˆåŠŸï¼"
    except Exception as e:
        return f"ç¼“å­˜æ¸…ç©ºå¤±è´¥ï¼š{str(e)}"

def upload_media(media_file, media_type):
    """ä¸Šä¼ åª’ä½“æ–‡ä»¶"""
    if media_file is None:
        return "è¯·é€‰æ‹©åª’ä½“æ–‡ä»¶", None, None
    
    try:
        if media_type == "è§†é¢‘":
            # ä¿å­˜è§†é¢‘æ–‡ä»¶
            temp_input_video = os.path.join(
                TEMP,
                os.path.splitext(os.path.basename(media_file.name))[0] + "_temp.mp4"
            )
            
            if not os.path.exists(temp_input_video):
                # å¤åˆ¶æ–‡ä»¶
                import shutil
                shutil.copy2(media_file.name, temp_input_video)
            
            app_state.video_temp_name = os.path.basename(media_file.name)
            app_state.video_temp = temp_input_video
            
            # æå–éŸ³é¢‘
            temp_audio_path = os.path.join(
                TEMP,
                os.path.splitext(os.path.basename(media_file.name))[0] + ".wav"
            )
            
            if not os.path.exists(temp_audio_path):
                extract_audio(temp_input_video, temp_audio_path)
            
            app_state.audio_temp = temp_audio_path
            return f"è§†é¢‘ä¸Šä¼ æˆåŠŸï¼š{media_file.name}\néŸ³é¢‘æå–å®Œæˆ", temp_audio_path, None
            
        else:  # éŸ³é¢‘
            temp_audio_path = os.path.join(
                TEMP,
                os.path.splitext(os.path.basename(media_file.name))[0] + ".wav"
            )
            
            if not os.path.exists(temp_audio_path):
                import shutil
                shutil.copy2(media_file.name, temp_audio_path)
            
            app_state.audio_temp = temp_audio_path
            return f"éŸ³é¢‘ä¸Šä¼ æˆåŠŸï¼š{media_file.name}", temp_audio_path, None
            
    except Exception as e:
        return f"åª’ä½“ä¸Šä¼ å¤±è´¥ï¼š{str(e)}", None, None

def clean_audio():
    """éŸ³é¢‘æ¸…æ´ï¼ˆå»é™¤èƒŒæ™¯éŸ³ï¼‰"""
    if app_state.audio_temp is None:
        error_msg = "è¯·å…ˆä¸Šä¼ åª’ä½“æ–‡ä»¶"
        print(f"[ERROR] {error_msg}")
        return error_msg, None
    
    try:
        if app_state.uvr_client is None:
            print("[INFO] å¼€å§‹åŠ è½½UVRæ¨¡å‹...")
            app_state.uvr_client = UVR_Client()
            print("[INFO] UVRæ¨¡å‹åŠ è½½å®Œæˆ")
        
        print(f"[INFO] å¼€å§‹å¤„ç†éŸ³é¢‘æ–‡ä»¶: {app_state.audio_temp}")
        primary_stem_output_path, secondary_stem_output_path = app_state.uvr_client.infer(app_state.audio_temp)
        app_state.audio_separator_temp = os.path.join('./temp', secondary_stem_output_path)
        
        print(f"[INFO] éŸ³é¢‘æ¸…æ´å®Œæˆï¼Œè¾“å‡ºæ–‡ä»¶: {app_state.audio_separator_temp}")
        return "éŸ³é¢‘æ¸…æ´å®Œæˆ", app_state.audio_separator_temp
    except Exception as e:
        # è·å–å®Œæ•´çš„é”™è¯¯å †æ ˆä¿¡æ¯
        error_traceback = traceback.format_exc()
        error_msg = f"éŸ³é¢‘æ¸…æ´å¤±è´¥ï¼š{str(e)}"
        
        # åœ¨ç»ˆç«¯è¾“å‡ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
        print(f"[ERROR] {error_msg}")
        print(f"[ERROR] è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        print(error_traceback)
        
        # é’ˆå¯¹ç‰¹å®šé”™è¯¯æä¾›è§£å†³å»ºè®®
        if 'roformer_download_list' in str(e).lower() or 'audio-separatoråº“ç‰ˆæœ¬ä¸å…¼å®¹' in str(e):
            suggestion = "\nå»ºè®®è§£å†³æ–¹æ¡ˆï¼š\n1. è¿™æ˜¯audio-separatoråº“ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜\n2. è¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ä¿®å¤ï¼š\n   pip uninstall audio-separator\n   pip install audio-separator==0.16.5\n3. é‡å¯åº”ç”¨ç¨‹åº\n4. å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·æ£€æŸ¥Pythonç¯å¢ƒ"
            print(f"[SUGGESTION] {suggestion}")
            error_msg += suggestion
        elif 'model' in str(e).lower():
            suggestion = "\nå»ºè®®è§£å†³æ–¹æ¡ˆï¼š\n1. æ£€æŸ¥ models/uvr5_weights ç›®å½•ä¸‹çš„æ¨¡å‹æ–‡ä»¶\n2. é‡æ–°ä¸‹è½½æ¨¡å‹æ–‡ä»¶\n3. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æƒé™"
            print(f"[SUGGESTION] {suggestion}")
            error_msg += suggestion
        
        return error_msg, None

def toggle_model_source(model_source):
    """åˆ‡æ¢æ¨¡å‹æ¥æºæ˜¾ç¤º"""
    if model_source == "é¢„è®¾æ¨¡å‹":
        return gr.update(visible=True), gr.update(visible=False)
    else:
        return gr.update(visible=False), gr.update(visible=True)

def setup_translation(translation_type, chat_url, chat_key, chat_model, baidu_appid, baidu_appkey, tencent_appid, tencent_secretkey):
    """è®¾ç½®ç¿»è¯‘å¼•æ“"""
    try:
        if translation_type == "å¦":
            app_state.engine = None
            return "å·²å…³é—­ç¿»è¯‘åŠŸèƒ½"
        elif translation_type == "GPTç¿»è¯‘":
            if not chat_key:
                return "è¯·è¾“å…¥GPT API Key"
            app_state.engine = GPT(key=chat_key, base_url=chat_url, model=chat_model)
            return f"GPTç¿»è¯‘å¼•æ“è®¾ç½®æˆåŠŸ (æ¨¡å‹: {chat_model})"
        elif translation_type == "ç™¾åº¦ç¿»è¯‘":
            if not baidu_appid or not baidu_appkey:
                return "è¯·è¾“å…¥ç™¾åº¦ç¿»è¯‘çš„AppIDå’ŒAppKey"
            app_state.engine = Baidu(appid=baidu_appid, secretKey=baidu_appkey)
            return "ç™¾åº¦ç¿»è¯‘å¼•æ“è®¾ç½®æˆåŠŸ"
        elif translation_type == "è…¾è®¯ç¿»è¯‘":
            if not tencent_appid or not tencent_secretkey:
                return "è¯·è¾“å…¥è…¾è®¯ç¿»è¯‘çš„AppIDå’ŒSecretKey"
            app_state.engine = Tencent(appid=tencent_appid, secretKey=tencent_secretkey)
            return "è…¾è®¯ç¿»è¯‘å¼•æ“è®¾ç½®æˆåŠŸ"
    except Exception as e:
        return f"ç¿»è¯‘å¼•æ“è®¾ç½®å¤±è´¥ï¼š{str(e)}"

def process_subtitle(language, vad_filter, min_silence_duration, text_split, split_method, prompt, show_video):
    """å¤„ç†å­—å¹•ç”Ÿæˆ"""
    if app_state.transcribe is None:
        return "è¯·å…ˆåŠ è½½æ¨¡å‹", None, None, None
    
    # é€‰æ‹©éŸ³é¢‘æº
    if app_state.audio_separator_temp is not None:
        input_audio = app_state.audio_separator_temp
    elif app_state.audio_temp is not None:
        input_audio = app_state.audio_temp
    else:
        return "è¯·å…ˆä¸Šä¼ åª’ä½“æ–‡ä»¶", None, None, None
    
    try:
        # è¯­è¨€æ˜ å°„
        language_mapping = {"ä¸­æ–‡": "zh", "æ—¥æ–‡": "ja", "è‹±æ–‡": "en"}
        lang_code = language_mapping[language]
        
        # VADè®¾ç½®
        is_vad_filter = vad_filter == "æ˜¯"
        min_silence_ms = min_silence_duration if is_vad_filter else None
        
        # æ–‡æœ¬åˆ†å‰²è®¾ç½®
        is_split = text_split == "æ˜¯"
        
        # æç¤ºè¯å¤„ç†
        initial_prompt = prompt if prompt.strip() else None
        
        print(f"å¼€å§‹å¤„ç†éŸ³é¢‘ï¼š{input_audio}")
        
        # ç”Ÿæˆå­—å¹•
        srt, ass = app_state.transcribe.run(
            file_name=input_audio,
            audio_binary_io=input_audio,
            language=lang_code,
            is_vad_filter=is_vad_filter,
            min_silence_duration_ms=min_silence_ms,
            is_split=is_split,
            split_method=split_method,
            initial_prompt=initial_prompt
        )
        
        # åˆ›å»ºä¸‹è½½åŒ…
        zip_name = os.path.splitext(os.path.basename(app_state.audio_temp))[0] + ".zip"
        zip_name_path = os.path.join("./temp", zip_name)
        
        with ZipFile(zip_name_path, "w") as zipObj:
            zipObj.write(srt, os.path.basename(srt))
            zipObj.write(ass, os.path.basename(ass))
            
            # å¦‚æœéœ€è¦ç¿»è¯‘
            if app_state.engine is not None:
                print("å¼€å§‹ç¿»è¯‘...")
                t = translation(app_state.engine)
                translate_ass, translate_srt = t.translate_save(ass)
                zipObj.write(translate_ass, os.path.basename(translate_ass))
                zipObj.write(translate_srt, os.path.basename(translate_srt))
        
        result_message = f"å­—å¹•ç”Ÿæˆå®Œæˆï¼\nåŸå§‹å­—å¹•ï¼š{os.path.basename(srt)}\n"
        if app_state.engine is not None:
            result_message += "ç¿»è¯‘å­—å¹•å·²ç”Ÿæˆ\n"
        result_message += "\nå¯ä»¥ä½¿ç”¨ Aegisub è¿›è¡ŒåæœŸç¼–è¾‘ä¼˜åŒ–"
        
        # ç”Ÿæˆå¸¦å­—å¹•çš„è§†é¢‘ï¼ˆå¦‚æœéœ€è¦ï¼‰
        output_video = None
        if app_state.video_temp and show_video == "æ˜¯":
            try:
                output_video_path = os.path.join(
                    TEMP,
                    os.path.splitext(os.path.basename(app_state.video_temp_name))[0] + "_output.mp4"
                )
                merge_subtitles_to_video(app_state.video_temp, ass, output_video_path)
                if os.path.exists(output_video_path):
                    output_video = output_video_path
            except Exception as e:
                print(f"è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼š{e}")
        
        return result_message, zip_name_path, srt, output_video
        
    except Exception as e:
        return f"å­—å¹•ç”Ÿæˆå¤±è´¥ï¼š{str(e)}", None, None, None

def create_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    
    with gr.Blocks(title="AIå­—å¹•ç”Ÿæˆå™¨", theme=gr.themes.Ocean()) as demo:
        gr.Markdown("# ğŸ¬ AIå­—å¹•ç”Ÿæˆå™¨")
        gr.Markdown("åŸºäºWhisperçš„æ™ºèƒ½å­—å¹•ç”Ÿæˆå·¥å…·ï¼Œæ”¯æŒå¤šç§è¯­è¨€è¯†åˆ«å’Œç¿»è¯‘")
        
        with gr.Tabs():
            # é…ç½®æ ‡ç­¾é¡µ
            with gr.TabItem("âš™ï¸ é…ç½®ç®¡ç†"):
                gr.Markdown("### é…ç½®æ–‡ä»¶ç®¡ç†")
                with gr.Row():
                    config_file = gr.File(label="ä¸Šä¼ é…ç½®æ–‡ä»¶ (JSON)", file_types=[".json"])
                    clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºç¼“å­˜", variant="secondary")
                
                config_status = gr.Textbox(label="é…ç½®çŠ¶æ€", interactive=False)
                
                gr.Markdown("### æ¨¡å‹é…ç½®")
                gr.Markdown(
                    "å¦‚æœæœ¬åœ°modelsç›®å½•ä¸­æ²¡æœ‰æ¨¡å‹ï¼Œå°†è‡ªåŠ¨ä»HuggingFaceä¸‹è½½ã€‚\n"
                    "ä¹Ÿå¯ä»¥æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹åˆ°modelsç›®å½•ï¼Œæˆ–é€‰æ‹©è‡ªå®šä¹‰å¾®è°ƒæ¨¡å‹ã€‚\n"
                )
                
                # æ¨¡å‹é€‰æ‹©æ–¹å¼
                model_source = gr.Radio(
                    choices=["é¢„è®¾æ¨¡å‹", "è‡ªå®šä¹‰æ¨¡å‹"],
                    value="é¢„è®¾æ¨¡å‹",
                    label="æ¨¡å‹æ¥æº"
                )
                
                # é¢„è®¾æ¨¡å‹é€‰æ‹©
                with gr.Group(visible=True) as preset_model_group:
                    with gr.Row():
                        model_name = gr.Dropdown(
                            choices=app_state.model_list,
                            value="large-v3",
                            label="é€‰æ‹©é¢„è®¾æ¨¡å‹ï¼ˆæ¨èä½¿ç”¨large-v3è·å¾—æœ€ä½³æ•ˆæœï¼‰"
                        )
                        device_name = gr.Dropdown(
                            choices=["cpu", "cuda"],
                            value="cuda",
                            label="è®¡ç®—è®¾å¤‡ï¼ˆå¼ºçƒˆå»ºè®®ä½¿ç”¨CUDAåŠ é€Ÿï¼‰"
                        )
                
                # è‡ªå®šä¹‰æ¨¡å‹é€‰æ‹©
                with gr.Group(visible=False) as custom_model_group:
                    gr.Markdown(
                        "#### ğŸ“ è‡ªå®šä¹‰æ¨¡å‹ä½¿ç”¨è¯´æ˜\n"
                        "- **faster-whisperæ ¼å¼**ï¼šåŒ…å«config.jsonã€model.binã€tokenizer.jsonç­‰æ–‡ä»¶çš„æ–‡ä»¶å¤¹\n"
                        "- **HuggingFaceæ ¼å¼**ï¼šåŒ…å«pytorch_model.binã€config.jsonã€tokenizer.jsonç­‰æ–‡ä»¶çš„æ–‡ä»¶å¤¹\n"
                        "- **æ”¯æŒå¾®è°ƒæ¨¡å‹**ï¼šä½¿ç”¨OpenAI Whisperã€faster-whisperæˆ–transformersåº“è®­ç»ƒçš„æ¨¡å‹\n"
                        "- **è·¯å¾„ç¤ºä¾‹**ï¼š`./models/my-whisper-model` æˆ– `D:/models/fine-tuned-whisper`"
                    )
                    custom_model_path = gr.Textbox(
                        label="è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„",
                        placeholder="è¯·è¾“å…¥æœ¬åœ°å¾®è°ƒæ¨¡å‹çš„æ–‡ä»¶å¤¹è·¯å¾„ï¼Œä¾‹å¦‚ï¼š./models/my-fine-tuned-whisper",
                        info="æ”¯æŒfaster-whisperæ ¼å¼å’ŒHuggingFace transformersæ ¼å¼çš„æœ¬åœ°æ¨¡å‹"
                    )
                    custom_device_name = gr.Dropdown(
                        choices=["cpu", "cuda"],
                        value="cuda",
                        label="è®¡ç®—è®¾å¤‡ï¼ˆå¼ºçƒˆå»ºè®®ä½¿ç”¨CUDAåŠ é€Ÿï¼‰"
                    )
                
                load_model_btn = gr.Button("ğŸš€ åŠ è½½æ¨¡å‹", variant="primary")
                model_status = gr.Textbox(label="æ¨¡å‹çŠ¶æ€", interactive=False)
            
            # åª’ä½“ä¸Šä¼ æ ‡ç­¾é¡µ
            with gr.TabItem("ğŸ“ åª’ä½“ä¸Šä¼ "):
                gr.Markdown("### é€‰æ‹©åª’ä½“ç±»å‹")
                media_type = gr.Radio(
                    choices=["è§†é¢‘", "éŸ³é¢‘"],
                    value="è§†é¢‘",
                    label="åª’ä½“ç±»å‹ï¼ˆæ”¯æŒè§†é¢‘æ ¼å¼ï¼šmp4, avi, mov, mkvï¼›éŸ³é¢‘æ ¼å¼ï¼šmp3, wav, m4aï¼‰"
                )
                
                media_file = gr.File(
                    label="ä¸Šä¼ åª’ä½“æ–‡ä»¶",
                    file_types=[".mp4", ".avi", ".mov", ".mkv", ".mp3", ".wav", ".m4a"]
                )
                
                upload_status = gr.Textbox(label="ä¸Šä¼ çŠ¶æ€", interactive=False)
                
                with gr.Row():
                    with gr.Column():
                        gr.Markdown("#### åŸå§‹éŸ³é¢‘")
                        original_audio = gr.Audio(label="æå–çš„éŸ³é¢‘", interactive=False)
                    
                    with gr.Column():
                        gr.Markdown("#### æ¸…æ´éŸ³é¢‘ï¼ˆå¯é€‰ï¼‰")
                        clean_audio_btn = gr.Button("ğŸ§¹ éŸ³é¢‘æ¸…æ´ï¼ˆå»é™¤èƒŒæ™¯éŸ³ä¹ï¼Œæé«˜è¯†åˆ«å‡†ç¡®åº¦ï¼‰")
                        cleaned_audio = gr.Audio(label="æ¸…æ´åçš„éŸ³é¢‘", interactive=False)
                
                clean_status = gr.Textbox(label="æ¸…æ´çŠ¶æ€", interactive=False)
            
            # è½¬å½•é…ç½®æ ‡ç­¾é¡µ
            with gr.TabItem("ğŸ¯ è½¬å½•é…ç½®"):
                gr.Markdown("### è¯­è¨€å’Œå¤„ç†è®¾ç½®")
                
                with gr.Row():
                    language = gr.Dropdown(
                        choices=["ä¸­æ–‡", "æ—¥æ–‡", "è‹±æ–‡"],
                        value="æ—¥æ–‡",
                        label="åª’ä½“è¯­è¨€ï¼ˆé€‰æ‹©éŸ³é¢‘/è§†é¢‘çš„ä¸»è¦è¯­è¨€ï¼‰"
                    )
                    
                    vad_filter = gr.Radio(
                        choices=["æ˜¯", "å¦"],
                        value="å¦",
                        label="å¯ç”¨VADè¿‡æ»¤ï¼ˆè¿‡æ»¤æ— å£°æ®µè½ï¼Œé¿å…è¯†åˆ«å‡ºæ— æ„ä¹‰å†…å®¹ï¼‰"
                    )
                
                min_silence_duration = gr.Slider(
                    minimum=0,
                    maximum=10000,
                    value=500,
                    step=100,
                    label="æœ€å°é™é»˜æ—¶é•¿ (æ¯«ç§’)ï¼ˆä»…åœ¨å¯ç”¨VADæ—¶ç”Ÿæ•ˆï¼‰",
                    visible=False
                )
                
                with gr.Row():
                    text_split = gr.Radio(
                        choices=["æ˜¯", "å¦"],
                        value="å¦",
                        label="æ–‡æœ¬åˆ†å‰²ï¼ˆå½“å•è¡Œæ–‡æœ¬è¿‡é•¿æ—¶å¯ç”¨ï¼‰"
                    )
                    
                    split_method = gr.Dropdown(
                        choices=["Modest", "Aggressive"],
                        value="Modest",
                        label="åˆ†å‰²æ–¹å¼ï¼ˆModest: æ™ºèƒ½åˆ†å‰²; Aggressive: é‡ç©ºæ ¼å°±åˆ†å‰²ï¼‰",
                        visible=False
                    )
                
                prompt = gr.Textbox(
                    label="æç¤ºè¯ï¼ˆå¸®åŠ©æ¨¡å‹æ›´å¥½åœ°è¯†åˆ«ç‰¹å®šå†…å®¹ï¼‰",
                    placeholder="ä¾‹å¦‚ï¼šç®€ä½“ä¸­æ–‡"
                )
                
                show_video = gr.Radio(
                    choices=["æ˜¯", "å¦"],
                    value="æ˜¯",
                    label="ç”Ÿæˆå¸¦å­—å¹•è§†é¢‘ï¼ˆä»…å¯¹è§†é¢‘æ–‡ä»¶æœ‰æ•ˆï¼‰"
                )
            
            # ç¿»è¯‘è®¾ç½®æ ‡ç­¾é¡µ
            with gr.TabItem("ğŸŒ ç¿»è¯‘è®¾ç½®"):
                gr.Markdown("### ç¿»è¯‘å¼•æ“é…ç½®")
                
                translation_type = gr.Radio(
                    choices=["å¦", "GPTç¿»è¯‘", "ç™¾åº¦ç¿»è¯‘", "è…¾è®¯ç¿»è¯‘"],
                    value="å¦",
                    label="ç¿»è¯‘é€‰é¡¹ï¼ˆé€‰æ‹©ç¿»è¯‘æœåŠ¡ï¼Œç¿»è¯‘ä¸ºä¸­æ–‡ï¼‰"
                )
                
                # GPTç¿»è¯‘é…ç½®
                with gr.Group(visible=False) as gpt_config:
                    gr.Markdown("#### GPTç¿»è¯‘é…ç½®")
                    with gr.Row():
                        chat_url = gr.Textbox(
                            label="Base URL",
                            value="https://api.openai.com/v1",
                            type="password"
                        )
                        chat_key = gr.Textbox(
                            label="API Key",
                            type="password"
                        )
                    chat_model = gr.Dropdown(
                        choices=["gpt-3.5-turbo", "gpt-4", "gpt-4-turbo"],
                        value="gpt-4-turbo",
                        label="æ¨¡å‹é€‰æ‹©"
                    )
                
                # ç™¾åº¦ç¿»è¯‘é…ç½®
                with gr.Group(visible=False) as baidu_config:
                    gr.Markdown("#### ç™¾åº¦ç¿»è¯‘é…ç½®")
                    gr.Markdown("[ç”³è¯·åœ°å€](https://fanyi-api.baidu.com/manage/developer)")
                    with gr.Row():
                        baidu_appid = gr.Textbox(label="AppID", type="password")
                        baidu_appkey = gr.Textbox(label="AppKey", type="password")
                
                # è…¾è®¯ç¿»è¯‘é…ç½®
                with gr.Group(visible=False) as tencent_config:
                    gr.Markdown("#### è…¾è®¯ç¿»è¯‘é…ç½®")
                    gr.Markdown("[ç”³è¯·åœ°å€](https://console.cloud.tencent.com/tmt)")
                    with gr.Row():
                        tencent_appid = gr.Textbox(label="AppID", type="password")
                        tencent_secretkey = gr.Textbox(label="SecretKey", type="password")
                
                setup_translation_btn = gr.Button("ğŸ”§ è®¾ç½®ç¿»è¯‘å¼•æ“", variant="secondary")
                translation_status = gr.Textbox(label="ç¿»è¯‘å¼•æ“çŠ¶æ€", interactive=False)
            
            # å¤„ç†ç»“æœæ ‡ç­¾é¡µ
            with gr.TabItem("ğŸ¬ å¤„ç†ä¸ç»“æœ"):
                gr.Markdown("### å¼€å§‹å¤„ç†")
                
                process_btn = gr.Button("ğŸš€ å¼€å§‹ç”Ÿæˆå­—å¹•", variant="primary", size="lg")
                
                process_status = gr.Textbox(label="å¤„ç†çŠ¶æ€", interactive=False)
                
                gr.Markdown("### ä¸‹è½½ç»“æœ")
                with gr.Row():
                    with gr.Column():
                        download_file = gr.File(label="ä¸‹è½½å­—å¹•åŒ… (ZIP)")
                        subtitle_preview = gr.File(label="å­—å¹•é¢„è§ˆ (SRT)")
                    
                    with gr.Column():
                        result_video = gr.Video(label="å¸¦å­—å¹•è§†é¢‘")
        
        # äº‹ä»¶ç»‘å®š
        
        # é…ç½®æ–‡ä»¶åŠ è½½
        config_file.change(
            fn=load_config,
            inputs=[config_file],
            outputs=[config_status, model_name, chat_url, chat_key, chat_model, 
                    baidu_appid, baidu_appkey, tencent_appid, tencent_secretkey]
        )
        
        # æ¸…ç©ºç¼“å­˜
        clear_btn.click(fn=clear_cache, outputs=[config_status])
        
        # æ¨¡å‹æ¥æºåˆ‡æ¢
        model_source.change(
            fn=toggle_model_source,
            inputs=[model_source],
            outputs=[preset_model_group, custom_model_group]
        )
        
        # åŠ è½½æ¨¡å‹ - åŠ¨æ€å¤„ç†é¢„è®¾æ¨¡å‹å’Œè‡ªå®šä¹‰æ¨¡å‹
        def handle_load_model(model_source, model_name, device_name, custom_model_path, custom_device_name):
            if model_source == "é¢„è®¾æ¨¡å‹":
                return load_model(model_name, device_name)
            else:
                return load_model(None, custom_device_name, custom_model_path)
        
        load_model_btn.click(
            fn=handle_load_model,
            inputs=[model_source, model_name, device_name, custom_model_path, custom_device_name],
            outputs=[model_status]
        )
        
        # åª’ä½“ä¸Šä¼ 
        media_file.change(
            fn=upload_media,
            inputs=[media_file, media_type],
            outputs=[upload_status, original_audio, cleaned_audio]
        )
        
        # éŸ³é¢‘æ¸…æ´
        clean_audio_btn.click(
            fn=clean_audio,
            outputs=[clean_status, cleaned_audio]
        )
        
        # VADè®¾ç½®æ˜¾ç¤º/éšè—
        def toggle_vad_settings(vad_choice):
            return gr.update(visible=(vad_choice == "æ˜¯"))
        
        vad_filter.change(
            fn=toggle_vad_settings,
            inputs=[vad_filter],
            outputs=[min_silence_duration]
        )
        
        # æ–‡æœ¬åˆ†å‰²è®¾ç½®æ˜¾ç¤º/éšè—
        def toggle_split_settings(split_choice):
            return gr.update(visible=(split_choice == "æ˜¯"))
        
        text_split.change(
            fn=toggle_split_settings,
            inputs=[text_split],
            outputs=[split_method]
        )
        
        # ç¿»è¯‘é…ç½®æ˜¾ç¤º/éšè—
        def toggle_translation_config(trans_type):
            return (
                gr.update(visible=(trans_type == "GPTç¿»è¯‘")),
                gr.update(visible=(trans_type == "ç™¾åº¦ç¿»è¯‘")),
                gr.update(visible=(trans_type == "è…¾è®¯ç¿»è¯‘"))
            )
        
        translation_type.change(
            fn=toggle_translation_config,
            inputs=[translation_type],
            outputs=[gpt_config, baidu_config, tencent_config]
        )
        
        # è®¾ç½®ç¿»è¯‘å¼•æ“
        setup_translation_btn.click(
            fn=setup_translation,
            inputs=[translation_type, chat_url, chat_key, chat_model,
                   baidu_appid, baidu_appkey, tencent_appid, tencent_secretkey],
            outputs=[translation_status]
        )
        
        # å¤„ç†å­—å¹•
        process_btn.click(
            fn=process_subtitle,
            inputs=[language, vad_filter, min_silence_duration, text_split, 
                   split_method, prompt, show_video],
            outputs=[process_status, download_file, subtitle_preview, result_video]
        )
    
    return demo

if __name__ == "__main__":
    # ç¡®ä¿tempç›®å½•å­˜åœ¨
    if not os.path.exists('temp'):
        os.makedirs('temp')
    
    # åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢
    demo = create_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        inbrowser=True
    )